"""
Camera Raw - é¢œè‰²è°ƒæ•´èŠ‚ç‚¹
"""

import torch
import numpy as np


class CameraRawColor:
    """Camera Raw é¢œè‰²è°ƒæ•´èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
            },
            "optional": {
                "ç™½å¹³è¡¡é¢„è®¾": (["åŽŸç…§è®¾ç½®", "è‡ªåŠ¨", "æ—¥å…‰", "é˜´å¤©", "é˜´å½±", "é’¨ä¸ç¯", "è§å…‰ç¯", "é—ªå…‰ç¯", "è‡ªå®šä¹‰"], {
                    "default": "åŽŸç…§è®¾ç½®"
                }),
                "è‰²æ¸©": ("FLOAT", {"default": 0.0, "min": -100.0, "max": 100.0, "step": 1.0}),
                "è‰²è°ƒ": ("FLOAT", {"default": 0.0, "min": -150.0, "max": 150.0, "step": 1.0}),
                "è‡ªç„¶é¥±å’Œåº¦": ("FLOAT", {"default": 0.0, "min": -100.0, "max": 100.0, "step": 1.0}),
                "é¥±å’Œåº¦": ("FLOAT", {"default": 0.0, "min": -100.0, "max": 100.0, "step": 1.0}),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "apply_color"
    CATEGORY = "ðŸ”µBB camera raw"
    
    def apply_color(self, image, ç™½å¹³è¡¡é¢„è®¾="åŽŸç…§è®¾ç½®", è‰²æ¸©=0.0, 
                   è‰²è°ƒ=0.0, è‡ªç„¶é¥±å’Œåº¦=0.0, é¥±å’Œåº¦=0.0):
        """åº”ç”¨é¢œè‰²è°ƒæ•´"""
        batch_size = image.shape[0]
        processed_images = []
        
        for i in range(batch_size):
            img = image[i].cpu().numpy()
            img_array = np.clip(img, 0.0, 1.0)
            
            # åº”ç”¨ç™½å¹³è¡¡é¢„è®¾
            if ç™½å¹³è¡¡é¢„è®¾ != "åŽŸç…§è®¾ç½®" and ç™½å¹³è¡¡é¢„è®¾ != "è‡ªå®šä¹‰":
                temp, tin = self._get_white_balance_preset(ç™½å¹³è¡¡é¢„è®¾)
                if è‰²æ¸© == 0.0:
                    è‰²æ¸© = temp
                if è‰²è°ƒ == 0.0:
                    è‰²è°ƒ = tin
            
            # åº”ç”¨è‰²æ¸©å’Œè‰²è°ƒ
            if è‰²æ¸© != 0.0 or è‰²è°ƒ != 0.0:
                img_array = self._apply_white_balance(img_array, è‰²æ¸©, è‰²è°ƒ)
            
            # åº”ç”¨è‡ªç„¶é¥±å’Œåº¦å’Œé¥±å’Œåº¦
            if è‡ªç„¶é¥±å’Œåº¦ != 0 or é¥±å’Œåº¦ != 0:
                img_array = self._adjust_saturation(img_array, è‡ªç„¶é¥±å’Œåº¦, é¥±å’Œåº¦)
            
            img_array = np.clip(img_array, 0.0, 1.0)
            processed_images.append(torch.from_numpy(img_array))
        
        return (torch.stack(processed_images),)
    
    def _get_white_balance_preset(self, preset):
        """èŽ·å–ç™½å¹³è¡¡é¢„è®¾å€¼"""
        presets = {
            "è‡ªåŠ¨": (0.0, 0.0),
            "æ—¥å…‰": (0.0, 0.0),
            "é˜´å¤©": (10.0, 0.0),
            "é˜´å½±": (20.0, 0.0),
            "é’¨ä¸ç¯": (-50.0, 0.0),
            "è§å…‰ç¯": (-30.0, 20.0),
            "é—ªå…‰ç¯": (0.0, 0.0),
        }
        return presets.get(preset, (0.0, 0.0))
    
    def _apply_white_balance(self, img, temperature, tint):
        """åº”ç”¨ç™½å¹³è¡¡"""
        if temperature != 0:
            temp_factor = temperature / 100.0
            if temp_factor > 0:
                img[:,:,2] = np.clip(img[:,:,2] - temp_factor * 0.1, 0, 1)
                img[:,:,0] = np.clip(img[:,:,0] + temp_factor * 0.05, 0, 1)
                img[:,:,1] = np.clip(img[:,:,1] + temp_factor * 0.05, 0, 1)
            else:
                img[:,:,2] = np.clip(img[:,:,2] - temp_factor * 0.1, 0, 1)
                img[:,:,0] = np.clip(img[:,:,0] + temp_factor * 0.05, 0, 1)
                img[:,:,1] = np.clip(img[:,:,1] + temp_factor * 0.05, 0, 1)
        
        if tint != 0:
            tint_factor = tint / 150.0
            img[:,:,1] = np.clip(img[:,:,1] - tint_factor * 0.05, 0, 1)
            img[:,:,0] = np.clip(img[:,:,0] + tint_factor * 0.05, 0, 1)
        
        return img
    
    def _adjust_saturation(self, img, vibrance, saturation):
        """è°ƒæ•´è‡ªç„¶é¥±å’Œåº¦å’Œé¥±å’Œåº¦"""
        max_channel = np.max(img, axis=2)
        min_channel = np.min(img, axis=2)
        delta = max_channel - min_channel
        current_saturation = np.where(max_channel > 0, delta / (max_channel + 1e-6), 0)
        
        if vibrance != 0:
            vibrance_factor = 1.0 + (vibrance / 100.0) * (1.0 - current_saturation)
            for c in range(3):
                img[:,:,c] = img[:,:,c] + (img[:,:,c] - max_channel) * (vibrance_factor - 1.0) * 0.5
        
        if saturation != 0:
            saturation_factor = 1.0 + (saturation / 100.0)
            for c in range(3):
                img[:,:,c] = max_channel + (img[:,:,c] - max_channel) * saturation_factor
        
        return img

"""
Camera Raw - äº®åº¦è°ƒæ•´èŠ‚ç‚¹
"""

import torch
import numpy as np
from PIL import Image, ImageEnhance


class CameraRawBrightness:
    """Camera Raw äº®åº¦è°ƒæ•´èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
            },
            "optional": {
                "æ›å…‰": ("FLOAT", {"default": 0.0, "min": -5.0, "max": 5.0, "step": 0.1}),
                "å¯¹æ¯”åº¦": ("FLOAT", {"default": 0.0, "min": -100.0, "max": 100.0, "step": 1.0}),
                "é«˜å…‰": ("FLOAT", {"default": 0.0, "min": -100.0, "max": 100.0, "step": 1.0}),
                "é˜´å½±": ("FLOAT", {"default": 0.0, "min": -100.0, "max": 100.0, "step": 1.0}),
                "ç™½è‰²": ("FLOAT", {"default": 0.0, "min": -100.0, "max": 100.0, "step": 1.0}),
                "é»‘è‰²": ("FLOAT", {"default": 0.0, "min": -100.0, "max": 100.0, "step": 1.0}),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "apply_brightness"
    CATEGORY = "ğŸ”µBB camera raw"
    
    def apply_brightness(self, image, æ›å…‰=0.0, å¯¹æ¯”åº¦=0.0, é«˜å…‰=0.0, 
                        é˜´å½±=0.0, ç™½è‰²=0.0, é»‘è‰²=0.0):
        """åº”ç”¨äº®åº¦è°ƒæ•´"""
        batch_size = image.shape[0]
        processed_images = []
        
        for i in range(batch_size):
            img = image[i].cpu().numpy()
            img = (img * 255.0).astype(np.uint8)
            pil_image = Image.fromarray(img)
            
            if æ›å…‰ != 0:
                exposure_factor = 2 ** æ›å…‰
                pil_image = ImageEnhance.Brightness(pil_image).enhance(exposure_factor)
            
            if å¯¹æ¯”åº¦ != 0:
                contrast_factor = 1.0 + (å¯¹æ¯”åº¦ / 100.0)
                pil_image = ImageEnhance.Contrast(pil_image).enhance(contrast_factor)
            
            img_array = np.array(pil_image, dtype=np.float32) / 255.0
            
            if é«˜å…‰ != 0 or é˜´å½± != 0:
                img_array = self._adjust_highlights_shadows(img_array, é«˜å…‰, é˜´å½±)
            
            if ç™½è‰² != 0 or é»‘è‰² != 0:
                img_array = self._adjust_whites_blacks(img_array, ç™½è‰², é»‘è‰²)
            
            img_array = np.clip(img_array, 0.0, 1.0)
            processed_images.append(torch.from_numpy(img_array))
        
        return (torch.stack(processed_images),)
    
    def _adjust_highlights_shadows(self, img, highlights, shadows):
        """è°ƒæ•´é«˜å…‰å’Œé˜´å½±"""
        gray = 0.299 * img[:,:,0] + 0.587 * img[:,:,1] + 0.114 * img[:,:,2]
        
        if highlights != 0:
            highlight_mask = np.maximum(gray - 0.5, 0) * 2
            highlight_factor = 1.0 + (highlights / 100.0) * highlight_mask[..., np.newaxis]
            img = img + (img * highlight_factor - img) * highlight_mask[..., np.newaxis]
        
        if shadows != 0:
            shadow_mask = np.maximum(0.5 - gray, 0) * 2
            shadow_factor = 1.0 + (shadows / 100.0) * shadow_mask[..., np.newaxis]
            img = img * (1 - shadow_mask[..., np.newaxis]) + img * shadow_factor * shadow_mask[..., np.newaxis]
        
        return img
    
    def _adjust_whites_blacks(self, img, whites, blacks):
        """è°ƒæ•´ç™½è‰²å’Œé»‘è‰²"""
        if whites != 0:
            white_factor = 1.0 + (whites / 100.0)
            img = np.power(img, 1.0 / white_factor)
        
        if blacks != 0:
            black_factor = 1.0 + (blacks / 100.0)
            img = np.power(img, black_factor)
        
        return img
